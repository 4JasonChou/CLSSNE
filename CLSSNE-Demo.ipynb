{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CLSSNE-Demo.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMjBYLxworVyt3wibx4Ej+m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UHc_xZbSAB1K","executionInfo":{"status":"ok","timestamp":1642752695984,"user_tz":-480,"elapsed":19257,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"5f9543c7-aea1-4770-ec6e-09b8fa14a90c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My\\ Drive/Colab\\ Notebooks/CLSSNE/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ib3luXn4AKu_","executionInfo":{"status":"ok","timestamp":1642752695984,"user_tz":-480,"elapsed":4,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"9b202ad2-da40-4a06-99f8-15ebee0e824f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/CLSSNE\n"]}]},{"cell_type":"code","source":["!pip install rouge\n","!pip install sentencepiece\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zsxk_FzsAKzO","executionInfo":{"status":"ok","timestamp":1642752708665,"user_tz":-480,"elapsed":12244,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"69cccdf8-ea2f-46c7-ca46-8a1f040eb488"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 9.6 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.2 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 76.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 54.7 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"]}]},{"cell_type":"code","source":["!pip install -U sentence-transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heyouSZZBP5s","executionInfo":{"status":"ok","timestamp":1642752712793,"user_tz":-480,"elapsed":4135,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"bd2db9f3-b496-48e6-ad68-471feec28784"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentence-transformers\n","  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n","\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 30 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 61 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 71 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 78 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.15.0)\n","Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.47)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.0.0)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n","Building wheels for collected packages: sentence-transformers\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=120999 sha256=c354743b2ae2173b95966038b2fd34148e23dac28327ca86d89895b65e8838f2\n","  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n","Successfully built sentence-transformers\n","Installing collected packages: sentence-transformers\n","Successfully installed sentence-transformers-2.1.0\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHiILgwiB8WY","executionInfo":{"status":"ok","timestamp":1642752714203,"user_tz":-480,"elapsed":1413,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"abf09636-b9c4-488e-e754-19924aad4274"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"uVbbWi3s_vlO","executionInfo":{"status":"ok","timestamp":1642752722105,"user_tz":-480,"elapsed":7905,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}}},"outputs":[],"source":["import sys\n","import os\n","import argparse\n","import pandas as pd\n","import pickle\n","import torch\n","import torch.nn as nn\n","import logging\n","import torch.nn.functional as F # 激勵函數\n","import datetime\n","import ast\n","from transformers import MBartConfig, MBart50Tokenizer, MBartForConditionalGeneration, AdamW\n","from transformers import  get_linear_schedule_with_warmup\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from rouge import Rouge\n","from sentence_transformers import SentenceTransformer\n","from nltk.tokenize import sent_tokenize\n","from sklearn.metrics.pairwise import cosine_similarity\n","from gensim.summarization import keywords\n","from sentence_transformers import SentenceTransformer\n","from nltk.tokenize import sent_tokenize"]},{"cell_type":"code","source":["# Load Model\n","mBartPars_name = \"model\"\n","mBartPars_config = \"{}/config.json\".format(mBartPars_name)\n","mBartPars_tokenizer = \"tokenizer\"\n","mBartPars_model = \"{}/pytorch_model.bin\".format(mBartPars_name)\n","mBartConfig = MBartConfig.from_pretrained(mBartPars_config)\n","mBartTokenizer = MBart50Tokenizer.from_pretrained(mBartPars_tokenizer, src_lang=\"en_XX\", tgt_lang=\"zh_CN\")\n","mBartModel = MBartForConditionalGeneration.from_pretrained(mBartPars_model, config = mBartConfig)\n","print( 'Init : Model, Tokenizer success.' )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQzj1xDw_87Y","executionInfo":{"status":"ok","timestamp":1642752771339,"user_tz":-480,"elapsed":49243,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"3f706ed9-0f89-47f5-d20c-e789e9918cc5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Init : Model, Tokenizer success.\n"]}]},{"cell_type":"code","source":["# Load to GPU\n","mDevice = torch.device(\"cuda\")\n","mBartModel.to(mDevice)\n","print('Init : Load model to Gpu success.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PE2e-BBBY07","executionInfo":{"status":"ok","timestamp":1642752784109,"user_tz":-480,"elapsed":12508,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"9f33eede-b4c9-4c20-95b7-07a26b4234a5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Init : Load model to Gpu success.\n"]}]},{"cell_type":"code","source":["def GetKeyword( article, nes ) :\n","    mSentences = sent_tokenize(article)\n","    mNameEntitys = ast.literal_eval(nes)\n","    finalSenteces = []\n","    for sen in mSentences :\n","        for ne in mNameEntitys :\n","            tmpRes = sen.find(ne)\n","            if tmpRes != -1 :\n","                finalSenteces.append(sen)\n","                break\n","    mergeText = ' '.join(finalSenteces)\n","    finalKeyword = keywords(mergeText).split('\\n')\n","    return finalKeyword\n","def NameEntitysHandler(neListStr) :\n","    neHints_tmp = ast.literal_eval(neListStr)\n","    neHints = ','.join(neHints_tmp)\n","    return neHints\n","\n","def NameEntitysHandlerWithSize(neHints_tmp) :\n","    if len(neHints_tmp) >= 3 : \n","        neHints_tmp = neHints_tmp[:3]\n","    neHints = ','.join(neHints_tmp)\n","    return neHints"],"metadata":{"id":"Bt31YQCcBdwE","executionInfo":{"status":"ok","timestamp":1642752821014,"user_tz":-480,"elapsed":286,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def PredictSummary( inputNameEntity, inputContext ):\n","    # tmpContext =  NameEntitysHandler(inputNameEntity) + '[CL]' + inputContext\n","    context_keyword = GetKeyword( inputContext, inputNameEntity )\n","    tmpContext =  NameEntitysHandler(inputNameEntity) + '[CL]' + NameEntitysHandlerWithSize(context_keyword) + '[CL]' + inputContext\n","    tmpInput = mBartTokenizer(tmpContext, max_length=522, pad_to_max_length=True, return_tensors='pt')\n","    tmpInput.to(mDevice)\n","    tmpOutput = mBartModel.generate( input_ids = tmpInput['input_ids'],\n","                                    attention_mask = tmpInput['attention_mask'],\n","                                    num_beams=4, max_length=120, repetition_penalty=1.2 ,early_stopping=True)\n","    tmpOutputStr = [ mBartTokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in tmpOutput ][0]\n","    print( inputNameEntity, \" : \", tmpOutputStr)"],"metadata":{"id":"DIun_Y70BjL2","executionInfo":{"status":"ok","timestamp":1642752824017,"user_tz":-480,"elapsed":705,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# ==== COVID-19 ====\n","\n","mArticle = '''\n","The Central Epidemic Command Center (CECC) yesterday announced a partial relaxation of the nation’s outdoor mask mandate as it reported zero new domestically transmitted COVID-19 cases.\n","Starting tomorrow, people would no longer need to wear masks in certain outdoor areas as long as social distancing can be maintained, said Minister of Health and Welfare Chen Shih-chung (陳時中), who heads the center.\n","Individuals in the agriculture, forestry, fishing and animal husbandry sectors who work in open spaces, such as fields and fish ponds, as well as people visiting forests and beaches, would not be required to wear masks, he said.\n","However, they would still have to carry a mask with them, as they would have to put it on if there is a sudden surge of people, he added.\n","Masks became a requirement for those using public transportation in April last year. A comprehensive outdoor mask mandate was introduced after Taiwan’s COVID-19 alert level was raised to level 3 in May, amid a spike in locally transmitted cases.\n","The alert level was lowered to level 2 on July 27, and several exceptions to mask requirements have since been announced, such as when having a meal, or when driving alone or with family members in an enclosed vehicle.\n","Further adjustments of mask requirements concerning specific occupations and religious events are to be announced today, Chen said.\n","Meanwhile, yesterday was the fourth consecutive day that zero new domestic cases have been reported, and the second straight day with no deaths, CECC data showed.\n","However, there were six new imported cases: two Taiwanese and four foreign nationals.\n","All six had recently arrived in Taiwan and tested positive during quarantine, the CECC said.\n","To date, Taiwan has confirmed a total of 16,250 COVID-19 cases, of which 14,417 were domestic infections reported after May 15, when the country first recorded more than 100 cases in a single day.\n","However, since Aug. 15, the daily number of domestic cases has mostly been in the single digits, totaling 114, CECC data showed.\n","With no new deaths reported yesterday, the number of confirmed COVID-19 deaths remained at 843, with all but 12 recorded since May 15, the data showed.\n","'''\n","\n","PredictSummary(\"['Chen Shih-chung']\",mArticle)\n","PredictSummary(\"['Taiwan','COVID-19','deaths']\",mArticle)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRK8VuVYBsZO","executionInfo":{"status":"ok","timestamp":1642752829977,"user_tz":-480,"elapsed":3645,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"633d12a4-37c6-407d-ad57-81ac28029abd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["['Chen Shih-chung']  :  zh_CN 卫生部长陈志强说,人们不再需要在某些户外区域戴口罩。农业、林业、渔业和动物饲养部门的个人不需要戴口罩。然而,他们仍然必须带着一个面具,如果突然有人闯入,他们必须戴上。\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["['Taiwan','COVID-19','deaths']  :  zh_CN 昨天没有新的COVID-19病例报告,这是连续第四天。迄今为止,台湾已确认总共有16,250例COVID-19病例。自5月15日以来,已确认的COVID-19死亡人数仍为843人,自5月15日以来只有12人死亡。\n"]}]},{"cell_type":"code","source":["mArticle = '''\n","A majority of Japanese feel friendly toward Taiwan, with almost half of respondents in a poll saying that they want to visit the country after COVID-19 travel curbs are eased, the Taipei Economic and Cultural Representative Office in Japan said yesterday.\n","The office said that 75.9 percent of respondents said they feel friendly toward Taiwan, citing as reasons the friendliness and politeness of Taiwanese, the long history of ties between the two nations, and the strength of bilateral trade.\n","More than one-quarter of respondents — 26.4 percent — said they had traveled to Taiwan, while 47.8 percent said they would like to once international travel resumes, the office said.\n","Regarding Taiwan-Japan relations, 71.4 percent of respondents said they are happy with the relationship, while 59.6 percent said they expect the ties to get a boost in the future, the office said.\n","The poll showed that 64.8 percent of respondents described Taiwan as “trustworthy,” citing as reasons Taiwan’s attitude toward Japan, shared democratic values and its peacefulness, it said.\n","Asked to choose the most friendly country in Asia, 46.6 percent of respondents chose Taiwan, 15.8 percent chose South Korea, 12.5 percent chose Singapore and 3 percent chose China, it said.\n","The poll showed that 65.1 percent of respondents agreed with Taipei’s assessment that trade between the two nations would get a boost if Taiwan joins the Comprehensive and Progressive Agreement for Trans-Pacific Partnership, it said.\n","Asked to choose which Taiwan-related issue is the most important to Japan, 40.7 percent said the country is most affected by the situation across the Taiwan Strait, while 8.2 percent cited fishery disputes and 6.8 cited economic competition, the office said.\n","Another 24.4 percent said there are no problems between Taiwan and Japan, it said.\n","Asked to select Taiwanese fruits they want to buy, 57.6 percent of respondents chose bananas, 57 percent chose pineapples and 44.2 percent chose mangoes, it said.\n","The office has since 2016 commissioned the Japan-based Central Research Services to conduct the annual survey on Japanese perception of Taiwan. This year’s poll utilized telephone interviews and Internet-based questionnaires, collecting responses from 1,000 Japanese aged 20 to 89.\n","'''\n","\n","PredictSummary(\"['Taiwan']\",mArticle)\n","PredictSummary(\"['Comprehensive']\",mArticle)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5WUmWx5UzaW","executionInfo":{"status":"ok","timestamp":1642746815891,"user_tz":-480,"elapsed":3993,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"10c542c7-3ef9-4a32-ce4e-d9a8e1469ef6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["['Taiwan']  :  zh_CN 79%的受访者表示,他们对台湾感到友好。理由是友好和礼貌以及两国关系的悠久历史。超过四分之一的受访者——26.4%——表示他们已经去过台湾。\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["['Comprehensive']  :  zh_CN 79%的受访者表示,他们对台湾友好,理由是台湾人的友好和礼貌以及两国关系的悠久历史。超过四分之一的受访者——26.4%——表示他们已经去过台湾,而47.8 %的人表示,他们希望一旦国际旅行简历被提交,就可以访问台湾。调查显示,65.1%的受访者同意台北的评估,即如果台湾加入跨太平洋伙伴关系全面协议,两国间的贸易将得到推动。\n"]}]},{"cell_type":"code","source":["mArticle = '''\n","A giant lantern shaped like a UFO that weighs more than 2 tonnes would be the main attraction at the Taipei Lantern Festival, which is to start in Taipei’s Shilin District (士林) on Feb. 11, the Taipei City Government said yesterday.\n","The UFO, which measures 7m in diameter and stands at 5m tall, lights up with spotlights and an array of LEDs, including panels that display the festival’s mascot, “Auspicious Tiger,” in the cockpit, Taipei Deputy Mayor Tsai Ping-kun (蔡炳坤) told a news conference.\n","The tiger is next lunar year’s zodiac animal, traditionally symbolizing vigor and vitality.\n","Festival creative director Akibo (李明道) said that the idea of the 2.5-tonne UFO was developed from an animation concept of a cosmic UFO that became lost in space and landed in Shilin.\n","Taipei then invited the travelers on the UFO to display the spacecraft as the festival’s main lantern, Akibo said.\n","“We hope it will spark the imagination of visitors and also give them an opportunity to broaden their horizons to give them unlimited possibilities,” Akibo said.\n","During the festival, the UFO would be the centerpiece of a three-minute show every 30 minutes in which it would be lifted 6m into the air to make it look like as if it is flying, Akibo said.\n","The UFO is one of Akibo’s many robotic-designed art installations across Taipei, including a Bluetooth speaker robot at Xinzhongshan Linear Park (心中山線形公園) and a treasure-finding airship at Taipei Children’s Amusement Park, Akibo said.\n","“When I was young, I didn’t have toys to play with, so when I grew up, I wanted to make a lot of big toys for myself and my children,” Akibo said.\n","The 10-day festival, which is to run through Feb. 20, would cover areas along three stations of the MRT railway serving metropolitan Taipei — including MRT Jiantan Station, which serves Shilin Night Market (士林夜市) — and showcase more than 50 lanterns and lantern artworks, the Taipei Department of Information and Tourism said in a statement.\n","The festival would also have two stage areas to host shows and performances, including by Golden Melody Award-winning artist Sanpuy Katatepan Mavaliyw and AKB48 Team TP, it added.\n","\n","'''\n","\n","PredictSummary(\"['UFO','Taipei']\",mArticle)\n","PredictSummary(\"['Akibo','Xinzhongshan ']\",mArticle)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c66xeslVtju","executionInfo":{"status":"ok","timestamp":1642747538803,"user_tz":-480,"elapsed":4817,"user":{"displayName":"周世傑","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07337862639600005060"}},"outputId":"f7e0d709-c7d5-491a-983a-261bdc5d06a3"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["['UFO','Taipei']  :  zh_CN 一个形状像不明飞行物的巨大灯笼将是台北灯笼节的主要吸引力。这种2.5吨重的不明飞行物直径为7米,高5米,用聚光灯和一系列发光二极管点亮。开幕式将于2月11日开始,为期10天的活动将展出50多件灯笼和灯笼艺术品。\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["['Akibo','Xinzhongshan ']  :  zh_CN 一个形状像不明飞行物的巨大灯笼将是台北灯笼节的主要吸引力。这只2.5吨重的不明飞行物直径为7米,长度为5米,用聚光灯和一系列发光二极管点亮。创意总监阿基博说,这个想法是基于一个在太空迷失的宇宙不明飞行物的动画概念。不明飞行物是阿基博在台北的许多机器人设计的艺术装置之一,包括兴盛山线性公园的一个蓝牙扬声器机器人。\n"]}]}]}